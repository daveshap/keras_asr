{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_asr.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/daveshap/keras_asr/blob/master/keras_asr.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "U9FGvvZk9OUs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras ASR Experiment\n",
        "\n",
        "## Step 1 - Setup Environment\n",
        "\n",
        "Your output should look something like this:\n",
        "\n",
        "```\n",
        "Redirecting output to ‘wget-log’.\n",
        "total 32\n",
        "drwxr-xr-x 1 root root 4096 Sep 21 17:57 .\n",
        "drwxr-xr-x 1 root root 4096 Sep 21 17:54 ..\n",
        "drwxr-xr-x 4 root root 4096 Sep 19 23:48 .config\n",
        "drwxr-xr-x 2 root root 4096 Sep 21 17:57 data\n",
        "drwxr-xr-x 3 root root 4096 Sep 21 17:56 LibriSpeech\n",
        "drwxr-xr-x 2 root root 4096 Sep 20 00:09 sample_data\n",
        "-rw-r--r-- 1 root root 6094 Sep 21 17:57 wget-log\n",
        " ```"
      ]
    },
    {
      "metadata": {
        "id": "wKzHlVuNQ5t8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4373e8fa-6dca-4bc1-c10a-2a6fdfd84b4f"
      },
      "cell_type": "code",
      "source": [
        "!wget -O - http://www.openslr.org/resources/12/dev-clean.tar.gz | tar xfz -\n",
        "!mkdir speech_data\n",
        "!ls -al\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install -y libsndfile-dev\n",
        "!pip install SoundFile -q\n",
        "!pip install librosa -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log.2’.\n",
            "mkdir: cannot create directory ‘speech_data’: File exists\n",
            "total 164\n",
            "drwxr-xr-x 1 root root   4096 Sep 21 21:20 .\n",
            "drwxr-xr-x 1 root root   4096 Sep 21 18:19 ..\n",
            "drwxr-xr-x 4 root root   4096 Sep 19 23:48 .config\n",
            "drwxr-xr-x 3 root root   4096 Sep 21 21:20 LibriSpeech\n",
            "drwxr-xr-x 2 root root   4096 Sep 20 00:09 sample_data\n",
            "drwxr-xr-x 2 root root 135168 Sep 21 21:07 speech_data\n",
            "-rw-r--r-- 1 root root   2174 Sep 21 21:04 wget-log\n",
            "-rw-r--r-- 1 root root   2254 Sep 21 21:05 wget-log.1\n",
            "-rw-r--r-- 1 root root   2174 Sep 21 21:20 wget-log.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "heTM3RWITJ1s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Import Modules\n",
        "\n",
        "Here we import modules and define a few things"
      ]
    },
    {
      "metadata": {
        "id": "fpVMMB0HOELl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc880612-370a-4f7a-9735-049d3e0f4f31"
      },
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "import librosa\n",
        "import pickle\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "\n",
        "libri_dir = './LibriSpeech/dev-clean'\n",
        "output_dir = './speech_data'\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "\n",
        "\n",
        "def get_file_paths(root_dir):\n",
        "    layer1 = os.listdir(root_dir)\n",
        "    results = []\n",
        "    for folder1 in layer1:\n",
        "        layer2 = os.listdir(root_dir + '/' + folder1)\n",
        "        for folder2 in layer2:\n",
        "            layer3 = os.listdir(root_dir + '/' + folder1 + '/' + folder2)\n",
        "            #print(layer3)\n",
        "            result = {'path': root_dir + '/' + folder1 + '/' + folder2, 'files': layer3}\n",
        "            results.append(result)\n",
        "    return results\n",
        "\n",
        "  \n",
        "data_dirs = get_file_paths(libri_dir)\n",
        "print(len(data_dirs))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iByogy6X6Vvh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Process Datasets\n",
        "This generates a bunch of pickle files where each contains 3 pieces of information\n",
        "* label (sentence string)\n",
        "* sample (MFCC as numpy ndarray)\n",
        "* encoded (result from Google Universal Encoder)"
      ]
    },
    {
      "metadata": {
        "id": "24IYMyzGTrEi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for folder in data_dirs:\n",
        "    samples = []\n",
        "    labels = []\n",
        "    print('FOLDER:', folder)\n",
        "    for file in folder['files']:\n",
        "        if 'flac' in file:\n",
        "            with open(folder['path'] + '/' + file, 'rb') as f:\n",
        "                data, samplerate = sf.read(f)\n",
        "                sample = librosa.feature.melspectrogram(y=data, sr=samplerate)\n",
        "                #sample = librosa.feature.mfcc(y=data, sr=samplerate)\n",
        "                samples.append({'data': sample, 'file': file})\n",
        "        if 'txt' in file:\n",
        "            with open(folder['path'] + '/' + file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                labels = lines\n",
        "    #print(samples)\n",
        "    #print(labels)\n",
        "    for entry in labels:\n",
        "        file = entry.split(' ')[0]\n",
        "        label = entry.replace(file, '').replace('\\\\n', '').strip().lower()\n",
        "        for record in samples:\n",
        "            if file in record['file']:\n",
        "                final = {'label': label, 'sample': record['data']}\n",
        "                with open(output_dir + '/' + file + '.pickle', 'wb') as outfile:\n",
        "                    pickle.dump(final, outfile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cTSy_Hwt7mAI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 4 - Generate Embeddings\n",
        "\n",
        "This step uses Google's Universal Sentence Encoder to generate **semantic vectors** from the sentence labels. Semantic vectors are consistently of size 512 and can represent any chunk of text."
      ]
    },
    {
      "metadata": {
        "id": "WYG0kztv7koo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "95c93b29-2b02-43b2-c9aa-9fe27ccf86c7"
      },
      "cell_type": "code",
      "source": [
        "embed = hub.Module(module_url)\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "files = os.listdir(output_dir)\n",
        "sentences = []\n",
        "max_len = 0\n",
        "\n",
        "print('loading all samples')\n",
        "for file in files:\n",
        "  with open(output_dir + '/' + file, 'rb') as infile:\n",
        "    d = pickle.load(infile)\n",
        "  sentences.append(d['label'])\n",
        "  if d['sample'].shape[1] > max_len:\n",
        "    max_len = d['sample'].shape[1]\n",
        "\n",
        "print('max length is:', max_len)\n",
        "print('getting encodings')\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  encoded = session.run(embed(sentences))\n",
        "  \n",
        "print('encoded', len(encoded), 'sentences')\n",
        "\n",
        "print('saving samples with embeddings')\n",
        "for i in range(len(files)):\n",
        "  with open(output_dir + '/' + files[i], 'rb') as infile:\n",
        "    d = pickle.load(infile)\n",
        "  d['embedding'] = encoded[i]\n",
        "  with open(output_dir + '/' + files[i], 'wb') as outfile:\n",
        "    pickle.dump(d, outfile)\n",
        "\n",
        "print('completed data prep!')\n",
        "\n",
        "with open(output_dir + '/' + files[10], 'rb') as testfile:\n",
        "  d = pickle.load(testfile)\n",
        "print('EXAMPLE FILE:')\n",
        "print('LABEL:     ', type(d['label']), d['label'])\n",
        "print('SAMPLE:    ', type(d['sample']), d['sample'].shape)\n",
        "print('EMBEDDING: ', type(d['embedding']), d['embedding'].shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
            "loading all samples\n",
            "max length is: 1021\n",
            "getting encodings\n",
            "encoded 2703 sentences\n",
            "saving samples with embeddings\n",
            "completed data prep!\n",
            "EXAMPLE FILE:\n",
            "LABEL:      <class 'str'> and if you have any desire to shorten the journey and put yourself easily in the way of salvation come with me and i will show you how to become a knight errant a calling wherein so many hardships and mishaps are encountered that if they be taken as penances they will lodge you in heaven in a trice\n",
            "SAMPLE:     <class 'numpy.ndarray'> (128, 648)\n",
            "EMBEDDING:  <class 'numpy.ndarray'> (512,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dxnGyV83eSSl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "b0f0e7c1-6109-45e4-80b7-51c9a69385e8"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "\n",
        "mfcc_features = 128\n",
        "max_len = 1021\n",
        "\n",
        "print('composing model')\n",
        "encoder = Sequential()\n",
        "\n",
        "encoder.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(128, 1021, 1)))\n",
        "encoder.add(Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
        "encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "encoder.add(Dropout(0.1))\n",
        "\n",
        "encoder.add(Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
        "encoder.add(Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
        "encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "encoder.add(Dropout(0.1))\n",
        "\n",
        "encoder.add(Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
        "encoder.add(Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
        "encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "encoder.add(Dropout(0.1))\n",
        "\n",
        "encoder.add(Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
        "encoder.add(Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
        "encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "encoder.add(Dropout(0.1))\n",
        "\n",
        "encoder.add(Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
        "encoder.add(Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
        "encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "encoder.add(Dropout(0.1))\n",
        "\n",
        "encoder.add(Flatten())\n",
        "encoder.add(Dense(512, activation='softmax'))\n",
        "encoder.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "print(encoder.summary())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "composing model\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 127, 1020, 32)     160       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 126, 1019, 32)     4128      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 63, 509, 32)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 63, 509, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 62, 508, 32)       4128      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 61, 507, 32)       4128      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 30, 253, 32)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 30, 253, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 29, 252, 32)       4128      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 251, 32)       4128      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 125, 32)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 14, 125, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 13, 124, 32)       4128      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 12, 123, 32)       4128      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 6, 61, 32)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 6, 61, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 5, 60, 32)         4128      \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 4, 59, 32)         4128      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 2, 29, 32)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 2, 29, 32)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1856)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               950784    \n",
            "=================================================================\n",
            "Total params: 988,096\n",
            "Trainable params: 988,096\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fA1GElneEBcE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 5 - Train Encoder\n",
        "The encoder is the heavy lifter. It looks at raw audio data in the form of an MFCC and encodes it to a semantic vector."
      ]
    },
    {
      "metadata": {
        "id": "r5YOGSO0ERDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c12caf28-5d23-4089-be34-9274151ed116"
      },
      "cell_type": "code",
      "source": [
        "print('compiling data')\n",
        "files = os.listdir(output_dir)\n",
        "data_x = []\n",
        "data_y = []\n",
        "for file in files:\n",
        "  with open(output_dir + '/' + file, 'rb') as infile:\n",
        "    dic = pickle.load(infile)\n",
        "  pad_width = max_len - dic['sample'].shape[1]\n",
        "  mfcc = np.pad(dic['sample'], pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "  data_x.append(mfcc)\n",
        "  data_y.append(dic['embedding'])\n",
        "\n",
        "data_x = np.asarray(data_x)\n",
        "data_y = np.asarray(data_y)\n",
        "\n",
        "data_x = np.expand_dims(data_x, axis=3)\n",
        "\n",
        "print('training model')\n",
        "encoder.fit(data_x, data_y, epochs=10, batch_size=32)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiling data\n",
            "training model\n",
            "Epoch 1/10\n",
            "2703/2703 [==============================] - 38s 14ms/step - loss: -44.2720 - acc: 0.0551\n",
            "Epoch 2/10\n",
            "2703/2703 [==============================] - 32s 12ms/step - loss: -47.2838 - acc: 0.0810\n",
            "Epoch 3/10\n",
            "2703/2703 [==============================] - 32s 12ms/step - loss: -47.5593 - acc: 0.0873\n",
            "Epoch 4/10\n",
            "2703/2703 [==============================] - 32s 12ms/step - loss: -48.0599 - acc: 0.0929\n",
            "Epoch 5/10\n",
            "2703/2703 [==============================] - 32s 12ms/step - loss: -48.4481 - acc: 0.0781\n",
            "Epoch 6/10\n",
            "2703/2703 [==============================] - 32s 12ms/step - loss: -48.7676 - acc: 0.0921\n",
            "Epoch 7/10\n",
            " 320/2703 [==>...........................] - ETA: 28s - loss: -50.0856 - acc: 0.0813"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}